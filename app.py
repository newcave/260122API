# ======================================================
# ALIO ì—°êµ¬ë³´ê³ ì„œ ìˆ˜ì§‘ + K-water í‘œì¤€ A ìš”ì•½ ì—ì´ì „íŠ¸
# (Bì•ˆ: ì‹¤ì œ ë™ì‘ ì—”ë“œí¬ì¸íŠ¸ ê¸°ë°˜ + ìë™ apbaType ì¶”ì¶œ + PDF ë§í¬ 2ì¤‘í™”)
# ======================================================

import os
import re
from dataclasses import dataclass
from io import BytesIO
from typing import Any, Dict, List, Optional, Tuple
from urllib.parse import urljoin

import requests
import streamlit as st
from bs4 import BeautifulSoup
import pdfplumber
from pypdf import PdfReader
from openai import OpenAI

# ======================================================
# App Config
# ======================================================
APP_TITLE = "ALIO ì—°êµ¬ë³´ê³ ì„œ ìš”ì•½ ì—ì´ì „íŠ¸ (K-water í‘œì¤€ A / Bì•ˆ ìë™ëŒ€ì‘)"
BASE = "https://www.alio.go.kr"

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
        "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    ),
    "Referer": BASE,
    "Accept": "application/json,text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
}

SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ìˆ˜ìì›ê³µì‚¬(K-water) ë° ê³µê³µê¸°ê´€ ì—°êµ¬ë³´ê³ ì„œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ì •ì±…Â·ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ë³´ê³ ì„œë¥¼ 'K-water ì—°êµ¬ë³´ê³ ì„œ í‘œì¤€ A ìš”ì•½ í˜•ì‹'ì— ë§ì¶° ìš”ì•½í•˜ì‹­ì‹œì˜¤.

[ì¶œë ¥ í˜•ì‹ â€” ë°˜ë“œì‹œ ì¤€ìˆ˜]

## 1. ì—°êµ¬ ë°°ê²½ ë° í•„ìš”ì„±
## 2. ì—°êµ¬ ëª©ì 
## 3. ì—°êµ¬ ë²”ìœ„ ë° ë°©ë²•
## 4. ì£¼ìš” ì—°êµ¬ ê²°ê³¼
## 5. ì •ì±…ì Â·ì‹¤ë¬´ì  ì‹œì‚¬ì 
## 6. ê²°ë¡  ë° í–¥í›„ ê³¼ì œ
"""

# ======================================================
# Models
# ======================================================
@dataclass
class ListProbeResult:
    endpoint: str
    method: str
    payload: Dict[str, Any]
    list_key: str
    total_key: Optional[str]
    apba_type: Optional[str]

@dataclass
class ReportCandidate:
    title: str
    org: str
    date: str
    detail_url: Optional[str]
    raw: Dict[str, Any]

# ======================================================
# HTTP helpers
# ======================================================
def safe_get(url: str, params: Optional[Dict[str, Any]] = None, timeout: int = 15) -> requests.Response:
    r = requests.get(url, params=params, headers=HEADERS, timeout=timeout, allow_redirects=True)
    r.raise_for_status()
    return r

def safe_post(url: str, data: Optional[Dict[str, Any]] = None, json_body: Optional[Dict[str, Any]] = None, timeout: int = 15) -> requests.Response:
    # ALIOëŠ” form-encodedë¥¼ ì“°ëŠ” ì¼€ì´ìŠ¤ê°€ ë§ì•„ì„œ data ìš°ì„ , í•„ìš” ì‹œ json_bodyë„ ì§€ì›
    r = requests.post(url, data=data, json=json_body, headers=HEADERS, timeout=timeout, allow_redirects=True)
    r.raise_for_status()
    return r

def is_json_response(resp: requests.Response) -> bool:
    ct = (resp.headers.get("Content-Type") or "").lower()
    if "application/json" in ct:
        return True
    try:
        resp.json()
        return True
    except Exception:
        return False

# ======================================================
# 0) apbaType ìë™ ì¶”ì¶œ (ê¸°ê´€/ë³´ê³ ì„œ í˜ì´ì§€ì—ì„œ íŒŒì‹±)
# ======================================================
def fetch_apba_type(apba_id: str, report_form_root_no: str) -> Optional[str]:
    """
    ê¸°ê´€/ë³´ê³ ì„œ ëª©ë¡ í˜ì´ì§€ HTML ì•ˆì— ì¡´ì¬í•˜ëŠ” apbaType ê°’ì„ ìµœëŒ€í•œ í­ë„“ê²Œ ì¶”ì¶œ
    """
    url = f"{BASE}/item/itemOrganList.do"
    params = {"apbaId": apba_id, "reportFormRootNo": report_form_root_no}
    r = safe_get(url, params=params)
    html = r.text

    patterns = [
        r"apbaType\s*[:=]\s*['\"]?([A-Za-z0-9]+)['\"]?",
        r"name=['\"]apbaType['\"][^>]*value=['\"]([^'\"]+)['\"]",
        r"['\"]apbaType['\"]\s*,\s*['\"]([^'\"]+)['\"]",  # ("apbaType","1") í˜•íƒœ
    ]
    for p in patterns:
        m = re.search(p, html)
        if m:
            return m.group(1)
    return None

# ======================================================
# 1) ëª©ë¡ API (ì‹¤ì œ ë™ì‘ ì—”ë“œí¬ì¸íŠ¸ ì¤‘ì‹¬) + ìë™ í”„ë¡œë¹™
# ======================================================
LIST_ENDPOINT_CANDIDATES = [
    (f"{BASE}/item/itemReportListSusi.json", "POST"),
    (f"{BASE}/item/itemReportList.json", "POST"),
]

# ì‹¤ì œ í˜ì´ì§€ë„¤ì´ì…˜ í‚¤ê°€ ë‹¤ì–‘í•´ì„œ í›„ë³´ë¥¼ ë„“ê²Œ ë‘ 
PAYLOAD_SETS = [
    # ê°€ì¥ í”í•œ ì¼€ì´ìŠ¤
    {"apbaId": None, "apbaType": None, "reportFormRootNo": None, "pageNo": 1, "pageCnt": 30},
    # ëŒ€ì²´ í‚¤
    {"apbaId": None, "apbaType": None, "reportFormRootNo": None, "pageIndex": 1, "pageSize": 30},
    {"apbaId": None, "apbaType": None, "reportFormRootNo": None, "curPage": 1, "pageSize": 30},
]

POSSIBLE_LIST_KEYS = ["list", "data", "result", "rows", "items"]
POSSIBLE_TOTAL_KEYS = ["totalCount", "total", "records", "count", "totCnt"]

def extract_list_from_json(data: Any) -> Tuple[Optional[List[Any]], Optional[str]]:
    if isinstance(data, list):
        return data, "(root_list)"
    if not isinstance(data, dict):
        return None, None

    # direct
    for k in POSSIBLE_LIST_KEYS:
        v = data.get(k)
        if isinstance(v, list):
            return v, k

    # nested
    for k, v in data.items():
        if isinstance(v, dict):
            for kk in POSSIBLE_LIST_KEYS:
                vv = v.get(kk)
                if isinstance(vv, list):
                    return vv, f"{k}.{kk}"

    return None, None

def guess_total_key(data: Any) -> Optional[str]:
    if not isinstance(data, dict):
        return None
    for tk in POSSIBLE_TOTAL_KEYS:
        if tk in data:
            return tk
    for k, v in data.items():
        if isinstance(v, dict):
            for tk in POSSIBLE_TOTAL_KEYS:
                if tk in v:
                    return f"{k}.{tk}"
    return None

def probe_report_list_api(apba_id: str, report_root: str, page_size: int) -> ListProbeResult:
    """
    endpoint + payload í›„ë³´ë¥¼ ìˆœíšŒí•˜ì—¬ ì‹¤ì œë¡œ listê°€ ë‚´ë ¤ì˜¤ëŠ” ì¡°í•©ì„ ì„ íƒ
    """
    apba_type = fetch_apba_type(apba_id, report_root)
    # fallback í›„ë³´: ì¼ë¶€ í˜ì´ì§€ì—ì„œ apbaTypeì´ ì•ˆ ì¡íˆëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„
    apba_type_candidates = [apba_type] if apba_type else []
    apba_type_candidates += ["1", "2", "A", "B"]  # ì•ˆì „ í›„ë³´(í™˜ê²½ë³„ í¸ì°¨ ëŒ€ì‘)

    last_err: Optional[Exception] = None

    for endpoint, method in LIST_ENDPOINT_CANDIDATES:
        for base_payload in PAYLOAD_SETS:
            for apba_type_try in apba_type_candidates:
                payload = dict(base_payload)
                payload["apbaId"] = apba_id
                payload["reportFormRootNo"] = report_root
                payload["apbaType"] = apba_type_try

                # page size ë°˜ì˜
                if "pageCnt" in payload:
                    payload["pageCnt"] = page_size
                if "pageSize" in payload:
                    payload["pageSize"] = page_size

                try:
                    if method == "POST":
                        resp = safe_post(endpoint, data=payload)  # form-encoded
                    else:
                        resp = safe_get(endpoint, params=payload)

                    if not is_json_response(resp):
                        continue

                    data = resp.json()
                    items, list_key = extract_list_from_json(data)

                    if items is None or not isinstance(items, list) or len(items) == 0:
                        # listê°€ ë¹„ë©´ ì‹¤íŒ¨ë¡œ ê°„ì£¼ (ê¸°ê´€/ìœ í˜•ì´ ì‹¤ì œë¡œ 0ê±´ì¸ ê²½ìš°ëŠ” ì˜ˆì™¸ì§€ë§Œ, ì—¬ê¸°ì„  "ë™ì‘ ì¡°í•© ì°¾ê¸°"ê°€ ëª©ì )
                        continue

                    return ListProbeResult(
                        endpoint=endpoint,
                        method=method,
                        payload=payload,
                        list_key=list_key or "",
                        total_key=guess_total_key(data),
                        apba_type=apba_type_try,
                    )
                except Exception as e:
                    last_err = e
                    continue

    raise RuntimeError(f"ëª©ë¡ API ìë™ íƒìƒ‰ ì‹¤íŒ¨ (ë§ˆì§€ë§‰ ì—ëŸ¬: {last_err})")

def fetch_list_with_probe(probe: ListProbeResult, page: int, page_size: int) -> Any:
    payload = dict(probe.payload)

    # í˜ì´ì§€ ë°˜ì˜
    if "pageNo" in payload:
        payload["pageNo"] = page
    elif "pageIndex" in payload:
        payload["pageIndex"] = page
    elif "curPage" in payload:
        payload["curPage"] = page

    if "pageCnt" in payload:
        payload["pageCnt"] = page_size
    if "pageSize" in payload:
        payload["pageSize"] = page_size

    if probe.method == "POST":
        resp = safe_post(probe.endpoint, data=payload)
    else:
        resp = safe_get(probe.endpoint, params=payload)

    if not is_json_response(resp):
        raise RuntimeError("ëª©ë¡ API ì‘ë‹µì´ JSONì´ ì•„ë‹™ë‹ˆë‹¤.")
    return resp.json()

def normalize_candidates(list_json: Any) -> List[ReportCandidate]:
    items, _ = extract_list_from_json(list_json)
    if not items:
        return []

    candidates: List[ReportCandidate] = []
    for it in items:
        if not isinstance(it, dict):
            continue

        title = (
            it.get("reportTitle")
            or it.get("rtitle")
            or it.get("title")
            or it.get("sj")
            or it.get("reportSj")
            or "(ì œëª©ì—†ìŒ)"
        )
        org = (
            it.get("apbaNm")
            or it.get("orgNm")
            or it.get("instNm")
            or it.get("org")
            or it.get("apbaName")
            or ""
        )
        date = (
            it.get("regDate")
            or it.get("regDt")
            or it.get("pubDate")
            or it.get("publishDate")
            or it.get("ymd")
            or it.get("wrtDt")
            or ""
        )

        # ìƒì„¸ URL í›„ë³´(ì—¬ëŸ¬ ì¼€ì´ìŠ¤ ëŒ€ì‘)
        detail_url = it.get("detailUrl") or it.get("detailURL") or it.get("linkUrl") or it.get("url")

        # ì–´ë–¤ ì‘ë‹µì€ itemDetail.doì— í•„ìš”í•œ í‚¤ë§Œ ì£¼ê³  URLì€ ì—†ì„ ìˆ˜ ìˆìŒ â†’ reportNo ê°™ì€ IDë¡œ êµ¬ì„±
        if not detail_url:
            # ê°€ëŠ¥í•œ ID í‚¤ë“¤
            rid = it.get("reportNo") or it.get("reportSn") or it.get("rptNo") or it.get("id") or it.get("seq")
            if rid:
                # ê³µí†µ ìƒì„¸ í˜ì´ì§€ íŒ¨í„´(ì—†ìœ¼ë©´ None ìœ ì§€)
                detail_url = f"{BASE}/item/itemDetail.do?reportNo={rid}"

        if isinstance(detail_url, str) and detail_url.startswith("/"):
            detail_url = urljoin(BASE, detail_url)

        candidates.append(
            ReportCandidate(
                title=str(title).strip(),
                org=str(org).strip(),
                date=str(date).strip(),
                detail_url=detail_url,
                raw=it,
            )
        )
    return candidates

# ======================================================
# 2) PDF ë§í¬ ì¶”ì¶œ: (A) ìƒì„¸ JSON í›„ë³´ë“¤ â†’ ì‹¤íŒ¨ì‹œ (B) ìƒì„¸ HTML íŒŒì‹±
# ======================================================
DETAIL_ENDPOINT_CANDIDATES = [
    f"{BASE}/item/itemReportDetail.json",
    f"{BASE}/item/itemReportView.json",
    f"{BASE}/iris/api/report/detail.json",
    f"{BASE}/iris/api/report/detail",
]

DETAIL_ID_KEYS = ["reportNo", "reportSn", "rptNo", "id", "seq", "reportId", "reportFormNo", "reportRootNo"]

def guess_id_fields(item: Dict[str, Any]) -> Dict[str, Any]:
    found = {}
    for k in DETAIL_ID_KEYS:
        if k in item and item[k] not in (None, "", 0):
            found[k] = item[k]
    return found

def extract_pdf_from_detail_json(detail_json: Any) -> Optional[str]:
    if not isinstance(detail_json, dict):
        return None

    # ì²¨ë¶€ ë¦¬ìŠ¤íŠ¸ êµ¬ì¡° í›„ë³´
    for key in ["attachFiles", "files", "fileList", "attachments"]:
        v = detail_json.get(key)
        if isinstance(v, list):
            for f in v:
                if not isinstance(f, dict):
                    continue
                ext = (f.get("fileExt") or f.get("ext") or "").lower()
                name = (f.get("fileNm") or f.get("name") or f.get("fileName") or "").lower()
                url = f.get("downloadUrl") or f.get("downUrl") or f.get("url")
                if isinstance(url, str) and url:
                    if ext == "pdf" or name.endswith(".pdf") or ".pdf" in url.lower():
                        return urljoin(BASE, url) if url.startswith("/") else url

    # ë‹¨ì¼ í•„ë“œ
    for key in ["pdfUrl", "pdfURL", "downloadUrl", "downUrl", "url"]:
        v = detail_json.get(key)
        if isinstance(v, str) and v and (".pdf" in v.lower() or "filedown" in v.lower() or "download" in v.lower()):
            return urljoin(BASE, v) if v.startswith("/") else v

    return None

def probe_detail_api_for_pdf(item: Dict[str, Any], apba_id: str, report_root: str, apba_type: Optional[str]) -> Optional[str]:
    id_fields = guess_id_fields(item)
    if not id_fields:
        return None

    param_candidates: List[Dict[str, Any]] = []

    # ìš°ì„ ìˆœìœ„ í‚¤
    for k in ["reportNo", "reportSn", "rptNo", "reportId", "id", "seq"]:
        if k in id_fields:
            param_candidates.append({k: id_fields[k]})

    # ì¶”ê°€ ì •ë³´ê°€ ìˆìœ¼ë©´ í•¨ê»˜ ë„£ëŠ” í›„ë³´ë„ ì‹œë„
    extras = {}
    if apba_id:
        extras["apbaId"] = apba_id
    if report_root:
        extras["reportFormRootNo"] = report_root
    if apba_type:
        extras["apbaType"] = apba_type

    if extras:
        for base in list(param_candidates):
            merged = dict(extras)
            merged.update(base)
            param_candidates.append(merged)

    # ìƒì„¸ API í›„ë³´ ìˆœíšŒ
    for endpoint in DETAIL_ENDPOINT_CANDIDATES:
        for params in param_candidates:
            try:
                # ìƒì„¸ëŠ” GET/POST í˜¼ì¬ ê°€ëŠ¥ â†’ GET ë¨¼ì €, ì‹¤íŒ¨ ì‹œ POST í•œ ë²ˆ ë”
                resp = safe_get(endpoint, params=params)
                if is_json_response(resp):
                    dj = resp.json()
                    pdf = extract_pdf_from_detail_json(dj)
                    if pdf:
                        return pdf

                resp2 = safe_post(endpoint, data=params)
                if is_json_response(resp2):
                    dj2 = resp2.json()
                    pdf2 = extract_pdf_from_detail_json(dj2)
                    if pdf2:
                        return pdf2
            except Exception:
                continue

    return None

def extract_pdf_links_from_detail_html(detail_url: str) -> List[str]:
    resp = safe_get(detail_url)
    html = resp.text
    soup = BeautifulSoup(html, "lxml")

    links: List[str] = []
    for a in soup.select("a[href]"):
        href = a.get("href", "")
        low = href.lower()
        if ".pdf" in low or "filedown" in low or "download" in low:
            links.append(urljoin(BASE, href) if href.startswith("/") else href)

    # JS/ë¬¸ìì—´ ì•ˆì˜ ë§í¬ë„ íƒìƒ‰
    for m in re.findall(r'(https?://[^\s"\']+)', html):
        if ".pdf" in m.lower() or "filedown" in m.lower() or "download" in m.lower():
            links.append(m)

    # download.json?fileNo=... í˜•íƒœë„ ì¡ê¸°
    for m in re.findall(r'(/download/[^"\']+)', html):
        if "fileNo=" in m or "download" in m.lower():
            links.append(urljoin(BASE, m))

    return list(dict.fromkeys(links))

def pick_best_pdf_link(links: List[str]) -> Optional[str]:
    if not links:
        return None
    for l in links:
        if ".pdf" in l.lower():
            return l
    return links[0]

# ======================================================
# PDF utilities
# ======================================================
def download_pdf_bytes(url: str, timeout: int = 25) -> bytes:
    r = requests.get(url, headers=HEADERS, timeout=timeout, allow_redirects=True)
    r.raise_for_status()
    return r.content

def extract_text_from_pdf(pdf_bytes: bytes) -> str:
    # 1) pdfplumber
    try:
        with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
            pages = [p.extract_text() or "" for p in pdf.pages]
        text = "\n".join(pages).strip()
        if text:
            return text
    except Exception:
        pass

    # 2) pypdf fallback
    reader = PdfReader(BytesIO(pdf_bytes))
    pages = [p.extract_text() or "" for p in reader.pages]
    return "\n".join(pages).strip()

def chunk_text(text: str, max_chars: int = 6000, overlap: int = 400) -> List[str]:
    chunks = []
    start = 0
    n = len(text)
    while start < n:
        end = min(start + max_chars, n)
        chunks.append(text[start:end])
        start = end - overlap if end < n else end
    return chunks

# ======================================================
# OpenAI summarization (new SDK)
# ======================================================
def get_openai_client() -> OpenAI:
    key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not key:
        raise RuntimeError("OPENAI_API_KEY not found in secrets/env")
    return OpenAI(api_key=key)

def summarize_kwater_standard_a(client: OpenAI, model: str, text: str) -> str:
    partial = []
    for chunk in chunk_text(text):
        r = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": chunk},
            ],
        )
        partial.append(r.output_text.strip())

    if len(partial) == 1:
        return partial[0]

    combined = "\n\n".join(partial)
    r = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": combined},
        ],
    )
    return r.output_text.strip()

# ======================================================
# Streamlit UI
# ======================================================
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ’§", layout="wide")
st.title(APP_TITLE)

with st.sidebar:
    st.header("ALIO ê²€ìƒ‰ ì„¤ì • (Bì•ˆ ìë™ëŒ€ì‘)")
    apba_id = st.text_input("ê¸°ê´€ ì½”ë“œ (apbaId)", value="C0221")
    report_root = st.text_input("ë³´ê³ ì„œ ìœ í˜• ì½”ë“œ (reportFormRootNo)", value="B1040")
    model = st.selectbox("ëª¨ë¸", ["gpt-4o-mini", "gpt-4o"], index=0)
    page_size = st.slider("í˜ì´ì§€ í¬ê¸°", 10, 50, 30, 5)
    st.divider()
    st.caption("â€» Bì•ˆì€ ì‹¤ì œ ë™ì‘ ì—”ë“œí¬ì¸íŠ¸(/item/*.json) + apbaType ìë™ ì¶”ì¶œ + í›„ë³´ í”„ë¡œë¹™ìœ¼ë¡œ ë™ì‘ ì¡°í•©ì„ ì°¾ìŠµë‹ˆë‹¤.")

# session state
if "probe" not in st.session_state:
    st.session_state.probe = None
if "candidates" not in st.session_state:
    st.session_state.candidates = []
if "last_debug" not in st.session_state:
    st.session_state.last_debug = {}

if st.button("1) ëª©ë¡ API ìë™ íƒìƒ‰ + ëª©ë¡ ì¡°íšŒ", type="primary"):
    try:
        probe = probe_report_list_api(apba_id, report_root, page_size=page_size)
        st.session_state.probe = probe

        list_json = fetch_list_with_probe(probe, page=1, page_size=page_size)
        candidates = normalize_candidates(list_json)
        st.session_state.candidates = candidates

        st.session_state.last_debug = {
            "chosen_endpoint": probe.endpoint,
            "method": probe.method,
            "payload_used": probe.payload,
            "apbaType_used": probe.apba_type,
            "list_key": probe.list_key,
            "total_key": probe.total_key,
        }

        if not candidates:
            st.warning("ëª©ë¡ ì‘ë‹µì€ ë°›ì•˜ì§€ë§Œ í•­ëª© íŒŒì‹± ê²°ê³¼ê°€ 0ê±´ì…ë‹ˆë‹¤. (ê¸°ê´€/ìœ í˜•ì´ ì‹¤ì œë¡œ 0ê±´ì¼ ìˆ˜ë„ ìˆìŒ)")
        else:
            st.success(f"ì¡°íšŒ ì„±ê³µ: {len(candidates)}ê±´")
    except Exception as e:
        st.error(f"ì¡°íšŒ ì‹¤íŒ¨: {e}")

if st.session_state.last_debug:
    with st.expander("ë””ë²„ê·¸: ìë™ ì„ íƒëœ ì‹¤ì œ ë™ì‘ ê°’(operating values)"):
        st.json(st.session_state.last_debug)

st.divider()
st.subheader("2) ë³´ê³ ì„œ ì„ íƒ â†’ PDF ì¶”ì¶œ(ìƒì„¸ JSON í”„ë¡œë¹™ â†’ ì‹¤íŒ¨ ì‹œ HTML íŒŒì‹±) â†’ ìš”ì•½")

if st.session_state.candidates:
    options = list(range(len(st.session_state.candidates)))
    idx = st.selectbox(
        "ë³´ê³ ì„œ ì„ íƒ",
        options,
        format_func=lambda i: f"{st.session_state.candidates[i].title} ({st.session_state.candidates[i].date}) {st.session_state.candidates[i].org}",
    )

    cand: ReportCandidate = st.session_state.candidates[idx]

    with st.expander("ì„ íƒ í•­ëª© ì›ë³¸(raw) ë³´ê¸°"):
        st.json(cand.raw)

    if st.button("PDF ì¶”ì¶œ + K-water í‘œì¤€ A ìš”ì•½"):
        try:
            probe: ListProbeResult = st.session_state.probe
            if not probe:
                raise RuntimeError("ë¨¼ì € 1) ëª©ë¡ ì¡°íšŒë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")

            # 1) ìƒì„¸ JSON í”„ë¡œë¹™ìœ¼ë¡œ PDF ë§í¬ ì¶”ì¶œ
            pdf_url = probe_detail_api_for_pdf(
                cand.raw,
                apba_id=apba_id,
                report_root=report_root,
                apba_type=probe.apba_type,
            )

            # 2) ì‹¤íŒ¨ ì‹œ ìƒì„¸ HTML íŒŒì‹±
            if not pdf_url:
                if not cand.detail_url:
                    raise RuntimeError("ìƒì„¸ URLì´ ì—†ì–´ HTML íŒŒì‹±ë„ ë¶ˆê°€í•©ë‹ˆë‹¤. (ëª©ë¡ JSONì— detailUrl/reportNoê°€ ì—†ìŒ)")
                links = extract_pdf_links_from_detail_html(cand.detail_url)
                pdf_url = pick_best_pdf_link(links)

            if not pdf_url:
                raise RuntimeError("PDF ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìƒì„¸ JSON/HTML ëª¨ë‘ì—ì„œ ì¶”ì¶œ ì‹¤íŒ¨)")

            st.info(f"PDF URL: {pdf_url}")

            pdf_bytes = download_pdf_bytes(pdf_url)
            text = extract_text_from_pdf(pdf_bytes).strip()
            if not text:
                st.warning("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (ìŠ¤ìº”ë³¸ ê°€ëŠ¥ì„±)")
                st.stop()

            client = get_openai_client()
            with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                summary = summarize_kwater_standard_a(client, model, text)

            st.markdown(summary)

            with st.expander("ì›ë¬¸ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°"):
                st.write(text[:1200])

        except Exception as e:
            st.error(f"ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
else:
    st.info("ë¨¼ì € '1) ëª©ë¡ API ìë™ íƒìƒ‰ + ëª©ë¡ ì¡°íšŒ'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
