import importlib.util
import os
from dataclasses import dataclass
from io import BytesIO
from typing import Any, List, Optional
from urllib.parse import urljoin, urlparse

import pdfplumber
import requests
import streamlit as st
from bs4 import BeautifulSoup
from pypdf import PdfReader

APP_TITLE = "K-water ë³´ê³ ì„œ ìš”ì•½ ì—ì´ì „íŠ¸"
SYSTEM_PROMPT = (
    "ë‹¹ì‹ ì€ ìˆ˜ìì› ë° ê³µê³µ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ë³´ê³ ì„œì˜ í•µì‹¬ ë‚´ìš©, "
    "ì—°êµ¬ ëª©ì , ê²°ë¡ ì„ ìš”ì•½í•˜ì—¬ Markdown í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”."
)
USER_AGENT = (
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
)


@dataclass
class ReportSource:
    pdf_url: Optional[str]
    text: str


def fetch_html(url: str, timeout: int = 12) -> str:
    response = requests.get(url, headers={"User-Agent": USER_AGENT}, timeout=timeout)
    response.raise_for_status()
    return response.text


def scrape_pdf_links(page_url: str) -> List[str]:
    html = fetch_html(page_url)
    soup = BeautifulSoup(html, "lxml")
    base_url = f"{urlparse(page_url).scheme}://{urlparse(page_url).netloc}"
    links = []
    for anchor in soup.select("a[href]"):
        href = anchor.get("href", "")
        lower_href = href.lower()
        if ".pdf" in lower_href or "filedown" in lower_href or "download" in lower_href:
            links.append(urljoin(base_url, href))
    deduped = list(dict.fromkeys(links))
    return deduped


def download_pdf(url: str, timeout: int = 20) -> bytes:
    response = requests.get(url, headers={"User-Agent": USER_AGENT}, timeout=timeout)
    response.raise_for_status()
    return response.content


def extract_text_from_pdf(pdf_bytes: bytes) -> str:
    with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
        pages_text = [page.extract_text() or "" for page in pdf.pages]
    text = "\n".join(pages_text).strip()
    if text:
        return text
    reader = PdfReader(BytesIO(pdf_bytes))
    pages_text = [page.extract_text() or "" for page in reader.pages]
    return "\n".join(pages_text).strip()


def chunk_text(text: str, max_chars: int = 6000, overlap: int = 400) -> List[str]:
    chunks = []
    start = 0
    text_length = len(text)
    while start < text_length:
        end = min(start + max_chars, text_length)
        chunk = text[start:end]
        chunks.append(chunk)
        start = end - overlap
        if start < 0:
            start = 0
        if end == text_length:
            break
    return chunks


def summarize_text(client: Any, model: str, text: str) -> str:
    chunks = chunk_text(text)
    summaries = []
    for chunk in chunks:
        response = client.chat.completions.create(
            model=model,
            messages=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": chunk},
            ],
        )
        summaries.append(response.choices[0].message.content.strip())
    if len(summaries) == 1:
        return summaries[0]
    combined = "\n\n".join(summaries)
    response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": combined},
        ],
    )
    return response.choices[0].message.content.strip()


def get_openai_client(api_key: str) -> Any:
    if importlib.util.find_spec("openai") is None:
        st.error("OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. requirements.txtë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    from openai import OpenAI

    return OpenAI(api_key=api_key)


st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ’§", layout="wide")

with st.sidebar:
    st.header("ì„¤ì •")
    api_key = st.text_input(
        "OpenAI API Key",
        type="password",
        value=st.secrets.get("OPENAI_API_KEY", os.getenv("OPENAI_API_KEY", "")),
        help="Streamlit Cloudì—ì„œëŠ” secrets.tomlì— ì €ì¥í•œ í‚¤ë¥¼ ìë™ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.",
    )
    model = st.selectbox("ëª¨ë¸", ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"], index=1)
    preview_limit = st.slider("í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸° ê¸¸ì´", min_value=300, max_value=2000, value=800)

st.title(APP_TITLE)

st.subheader("ë³´ê³ ì„œ ì…ë ¥")
url_input = st.text_input(
    "ALIO ê²Œì‹œê¸€ URL",
    placeholder="https://alio.go.kr/item/itemDetail.do?...",
)
uploaded_pdf = st.file_uploader("PDF íŒŒì¼ ì§ì ‘ ì—…ë¡œë“œ", type=["pdf"])

if "report_text" not in st.session_state:
    st.session_state.report_text = ""
if "report_source" not in st.session_state:
    st.session_state.report_source = None
if "summary" not in st.session_state:
    st.session_state.summary = ""
if "pdf_links" not in st.session_state:
    st.session_state.pdf_links = []
if "scrape_warning" not in st.session_state:
    st.session_state.scrape_warning = ""

load_button = st.button("ë³´ê³ ì„œ ë¶ˆëŸ¬ì˜¤ê¸°", type="primary")

if load_button:
    st.session_state.summary = ""
    st.session_state.report_text = ""
    st.session_state.report_source = None
    st.session_state.pdf_links = []
    st.session_state.scrape_warning = ""

    if not url_input and not uploaded_pdf:
        st.warning("URL ë˜ëŠ” PDF íŒŒì¼ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        if url_input:
            try:
                st.session_state.pdf_links = scrape_pdf_links(url_input)
                if not st.session_state.pdf_links:
                    st.session_state.scrape_warning = (
                        "ìŠ¤í¬ë˜í•‘ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. PDFë¥¼ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                    )
            except requests.RequestException:
                st.session_state.scrape_warning = (
                    "ìŠ¤í¬ë˜í•‘ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. PDFë¥¼ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”."
                )
        if uploaded_pdf is not None:
            pdf_bytes = uploaded_pdf.read()
            try:
                report_text = extract_text_from_pdf(pdf_bytes)
            except Exception:
                st.error("PDF íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
                report_text = ""
            if report_text:
                st.session_state.report_text = report_text
                st.session_state.report_source = ReportSource(
                    pdf_url="ì—…ë¡œë“œëœ íŒŒì¼",
                    text=report_text,
                )
            else:
                st.warning("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤ìº”ë³¸ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if st.session_state.scrape_warning:
    st.warning(st.session_state.scrape_warning)

if st.session_state.pdf_links:
    selected_pdf = st.selectbox("ë°œê²¬ëœ PDF ë§í¬", st.session_state.pdf_links)
    if st.button("ì„ íƒí•œ PDF ë¶ˆëŸ¬ì˜¤ê¸°"):
        try:
            pdf_bytes = download_pdf(selected_pdf)
            report_text = extract_text_from_pdf(pdf_bytes)
        except requests.RequestException:
            st.error("PDF ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. PDFë¥¼ ì§ì ‘ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            report_text = ""
        except Exception:
            st.error("PDF íŒŒì‹± ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
            report_text = ""
        if report_text:
            st.session_state.report_text = report_text
            st.session_state.report_source = ReportSource(
                pdf_url=selected_pdf,
                text=report_text,
            )
        else:
            st.warning("PDFì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìŠ¤ìº”ë³¸ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

if st.session_state.report_source:
    st.success("ë³´ê³ ì„œ ë¡œë”© ì™„ë£Œ")
    st.caption(f"ì‚¬ìš©í•œ ì†ŒìŠ¤: {st.session_state.report_source.pdf_url}")

st.divider()

st.subheader("ìš”ì•½")
if st.button("ìš”ì•½ ìƒì„±"):
    if not api_key:
        st.warning("OpenAI API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
    elif not st.session_state.report_text:
        st.warning("ë¨¼ì € ë³´ê³ ì„œë¥¼ ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
    else:
        try:
            client = get_openai_client(api_key)
            with st.spinner("ìš”ì•½ ìƒì„± ì¤‘..."):
                st.session_state.summary = summarize_text(
                    client, model, st.session_state.report_text
                )
        except Exception:
            st.error("ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. API Key ë˜ëŠ” ëª¨ë¸ì„ í™•ì¸í•˜ì„¸ìš”.")

if st.session_state.summary:
    st.markdown(st.session_state.summary)

if st.session_state.report_text:
    with st.expander("ì›ë³¸ í…ìŠ¤íŠ¸ ë¯¸ë¦¬ë³´ê¸°"):
        st.write(st.session_state.report_text[:preview_limit])
