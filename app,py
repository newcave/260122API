# ======================================================
# K-water ì—°êµ¬ë³´ê³ ì„œ ìš”ì•½ ì—ì´ì „íŠ¸ (í‘œì¤€ A)
# ======================================================

import os
from dataclasses import dataclass
from io import BytesIO
from typing import List, Optional
from urllib.parse import urljoin, urlparse

import pdfplumber
import requests
import streamlit as st
from bs4 import BeautifulSoup
from openai import OpenAI
from pypdf import PdfReader

# ======================================================
# App Config
# ======================================================
APP_TITLE = "K-water ì—°êµ¬ë³´ê³ ì„œ ìš”ì•½ ì—ì´ì „íŠ¸ (í‘œì¤€ A)"

USER_AGENT = (
    "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
    "(KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
)

# ======================================================
# K-water Standard A System Prompt
# ======================================================
SYSTEM_PROMPT = """
ë‹¹ì‹ ì€ í•œêµ­ìˆ˜ìì›ê³µì‚¬(K-water) ë° ê³µê³µê¸°ê´€ ì—°êµ¬ë³´ê³ ì„œë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ë¶„ì„í•˜ëŠ” ì •ì±…Â·ê¸°ìˆ  ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì•„ë˜ ë³´ê³ ì„œë¥¼ 'K-water ì—°êµ¬ë³´ê³ ì„œ í‘œì¤€ A ìš”ì•½ í˜•ì‹'ì— ë§ì¶° ìš”ì•½í•˜ì‹­ì‹œì˜¤.

[ìš”ì•½ ì‘ì„± ì›ì¹™]
- ê°ê´€ì ì´ê³  ê³µê³µê¸°ê´€ ë¬¸ì²´ ì‚¬ìš©
- ë¶ˆí•„ìš”í•œ ìˆ˜ì‹ì–´ ì œê±°
- ì •ì±…Â·ì‹¤ë¬´ í™œìš© ê´€ì  ê°•ì¡°
- Markdown í˜•ì‹ ì‚¬ìš©

[ì¶œë ¥ í˜•ì‹ â€” ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡° ìœ ì§€]

## 1. ì—°êµ¬ ë°°ê²½ ë° í•„ìš”ì„±
## 2. ì—°êµ¬ ëª©ì 
## 3. ì—°êµ¬ ë²”ìœ„ ë° ë°©ë²•
## 4. ì£¼ìš” ì—°êµ¬ ê²°ê³¼
## 5. ì •ì±…ì Â·ì‹¤ë¬´ì  ì‹œì‚¬ì 
## 6. ê²°ë¡  ë° í–¥í›„ ê³¼ì œ
"""

# ======================================================
# Data Model
# ======================================================
@dataclass
class ReportSource:
    pdf_url: Optional[str]
    text: str

# ======================================================
# Web & PDF Utilities
# ======================================================
def fetch_html(url: str, timeout: int = 12) -> str:
    response = requests.get(url, headers={"User-Agent": USER_AGENT}, timeout=timeout)
    response.raise_for_status()
    return response.text


def scrape_pdf_links(page_url: str) -> List[str]:
    html = fetch_html(page_url)
    soup = BeautifulSoup(html, "lxml")
    base_url = f"{urlparse(page_url).scheme}://{urlparse(page_url).netloc}"

    links = []
    for a in soup.select("a[href]"):
        href = a.get("href", "").lower()
        if ".pdf" in href or "filedown" in href or "download" in href:
            links.append(urljoin(base_url, a["href"]))

    return list(dict.fromkeys(links))


def download_pdf(url: str, timeout: int = 20) -> bytes:
    response = requests.get(url, headers={"User-Agent": USER_AGENT}, timeout=timeout)
    response.raise_for_status()
    return response.content


def extract_text_from_pdf(pdf_bytes: bytes) -> str:
    # 1) pdfplumber ìš°ì„ 
    try:
        with pdfplumber.open(BytesIO(pdf_bytes)) as pdf:
            text = "\n".join(page.extract_text() or "" for page in pdf.pages).strip()
        if text:
            return text
    except Exception:
        pass

    # 2) pypdf fallback
    reader = PdfReader(BytesIO(pdf_bytes))
    return "\n".join(page.extract_text() or "" for page in reader.pages).strip()


def chunk_text(text: str, max_chars: int = 6000, overlap: int = 400) -> List[str]:
    chunks = []
    start = 0
    length = len(text)

    while start < length:
        end = min(start + max_chars, length)
        chunks.append(text[start:end])
        start = end - overlap if end < length else end

    return chunks

# ======================================================
# OpenAI Summarization Logic
# ======================================================
def get_openai_client() -> OpenAI:
    api_key = st.secrets.get("OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise RuntimeError("OPENAI_API_KEY not found")
    return OpenAI(api_key=api_key)


def summarize_text(client: OpenAI, model: str, text: str) -> str:
    chunks = chunk_text(text)
    partial_summaries = []

    for chunk in chunks:
        response = client.responses.create(
            model=model,
            input=[
                {"role": "system", "content": SYSTEM_PROMPT},
                {"role": "user", "content": chunk},
            ],
        )
        partial_summaries.append(response.output_text.strip())

    # ë‹¨ì¼ ì²­í¬
    if len(partial_summaries) == 1:
        return partial_summaries[0]

    # í†µí•© ìš”ì•½
    combined = "\n\n".join(partial_summaries)

    final_response = client.responses.create(
        model=model,
        input=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": combined},
        ],
    )

    return final_response.output_text.strip()

# ======================================================
# Streamlit UI
# ======================================================
st.set_page_config(page_title=APP_TITLE, page_icon="ğŸ’§", layout="wide")
st.title(APP_TITLE)

with st.sidebar:
    st.header("ìš”ì•½ ì„¤ì •")
    model = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        ["gpt-4o-mini", "gpt-4o"],
        index=0,
    )
    preview_limit = st.slider("ì›ë¬¸ ë¯¸ë¦¬ë³´ê¸° ê¸¸ì´", 300, 2000, 800)

# ======================================================
# Input Section
# ======================================================
st.subheader("ë³´ê³ ì„œ ì…ë ¥")

url_input = st.text_input(
    "ALIO ê²Œì‹œê¸€ URL",
    placeholder="https://alio.go.kr/item/itemDetail.do?..."
)

uploaded_pdf = st.file_uploader("PDF ì§ì ‘ ì—…ë¡œë“œ", type=["pdf"])

# ======================================================
# Session State Init
# ======================================================
for key in ["report_text", "report_source", "summary", "pdf_links", "warning"]:
    if key not in st.session_state:
        st.session_state[key] = "" if key != "pdf_links" else []

# ======================================================
# Load Report
# ======================================================
if st.button("ë³´ê³ ì„œ ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
    st.session_state.summary = ""
    st.session_state.report_text = ""
    st.session_state.report_source = None
    st.session_state.pdf_links = []
    st.session_state.warning = ""

    if not url_input and not uploaded_pdf:
        st.warning("URL ë˜ëŠ” PDF íŒŒì¼ì„ ì…ë ¥í•˜ì„¸ìš”.")
    else:
        if url_input:
            try:
                st.session_state.pdf_links = scrape_pdf_links(url_input)
                if not st.session_state.pdf_links:
                    st.session_state.warning = "PDF ë§í¬ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            except Exception:
                st.session_state.warning = "ALIO í˜ì´ì§€ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤."

        if uploaded_pdf:
            try:
                text = extract_text_from_pdf(uploaded_pdf.read())
                st.session_state.report_text = text
                st.session_state.report_source = ReportSource("ì—…ë¡œë“œëœ íŒŒì¼", text)
            except Exception:
                st.error("PDF íŒŒì‹± ì‹¤íŒ¨")

# ======================================================
# PDF Selection
# ======================================================
if st.session_state.warning:
    st.warning(st.session_state.warning)

if st.session_state.pdf_links:
    selected_pdf = st.selectbox("ë°œê²¬ëœ PDF ëª©ë¡", st.session_state.pdf_links)
    if st.button("ì„ íƒí•œ PDF ë¶ˆëŸ¬ì˜¤ê¸°"):
        pdf_bytes = download_pdf(selected_pdf)
        text = extract_text_from_pdf(pdf_bytes)
        st.session_state.report_text = text
        st.session_state.report_source = ReportSource(selected_pdf, text)

if st.session_state.report_source:
    st.success("ë³´ê³ ì„œ ë¡œë”© ì™„ë£Œ")
    st.caption(f"ì†ŒìŠ¤: {st.session_state.report_source.pdf_url}")

# ======================================================
# Summarization
# ======================================================
st.divider()
st.subheader("í‘œì¤€ A ìš”ì•½ ê²°ê³¼")

if st.button("ìš”ì•½ ìƒì„±"):
    if not st.session_state.report_text:
        st.warning("ë³´ê³ ì„œë¥¼ ë¨¼ì € ë¶ˆëŸ¬ì˜¤ì„¸ìš”.")
    else:
        client = get_openai_client()
        with st.spinner("K-water í‘œì¤€ A ìš”ì•½ ìƒì„± ì¤‘..."):
            st.session_state.summary = summarize_text(
                client,
                model,
                st.session_state.report_text,
            )

if st.session_state.summary:
    st.markdown(st.session_state.summary)

if st.session_state.report_text:
    with st.expander("ì›ë¬¸ ë¯¸ë¦¬ë³´ê¸°"):
        st.write(st.session_state.report_text[:preview_limit])
